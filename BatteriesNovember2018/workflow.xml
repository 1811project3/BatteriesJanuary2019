
<workflow-app xmlns="uri:oozie:workflow:0.1" name="BatteryTest-wf">
    <start to='BatteryDenormalizerMapReduce'/>
    <action name='BatteryDenormalizerMapReduce'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${IntermediateDataOutput}"/>
            </prepare>
            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapreduce.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.reduce.class</name>
                    <value>com.revature.reducer.BatteryReducer</value>
                </property>
                <property>
                    <name>mapreduce.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.map.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.DelegatingMapper</value>
                </property>
                <property>
                    <name>mapred.reduce.tasks</name>
                    <value>1</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.input.key.class</name>
                    <value>org.apache.hadoop.io.LongWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.input.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.input.multipleinputs.dir.formats</name>
                    <value>${ViewBatteryPerformanceInput};org.apache.hadoop.mapreduce.lib.input.TextInputFormat,${ViewBatteryNoteInput};org.apache.hadoop.mapreduce.lib.input.TextInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.input.multipleinputs.dir.mappers</name>
                    <value>${ViewBatteryPerformanceInput};com.revature.mapper.BatteryMapper,${ViewBatteryNoteInput};com.revature.mapper.BatteryAAAMapper</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${IntermediateDataOutput}</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to='fork_node'/>
        <error to='kill'/>
    </action>

    <fork name = 'fork_node'>
        <path start = 'BatteryMedianMapReduce'/>
        <path start = 'BatteryOutliersMapReduce'/>
    </fork>

    <action name='BatteryMedianMapReduce'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${BatteryMedianOutput}"/>
            </prepare>
            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapreduce.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.map.class</name>
                    <value>com.revature.mapper.BatteryOutliersMapper</value>
                </property>
                <property>
                    <name>mapreduce.combine.class</name>
                    <value>com.revature.reducer.BatteryMedianCombiner</value>
                </property>
                <property>
                    <name>mapreduce.reduce.class</name>
                    <value>com.revature.reducer.BatteryMedianReducer</value>
                </property>
                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.TextInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.input.key.class</name>
                    <value>org.apache.hadoop.io.LongWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.input.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${IntermediateDataOutput}/part-r-00000</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${BatteryMedianOutput}</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to='join_node'/>
        <error to='kill'/>
    </action>

    <action name='BatteryOutliersMapReduce'>
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${BatteryOutlierOutput}"/>
            </prepare>
            <configuration>
                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapreduce.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>mapreduce.map.class</name>
                    <value>com.revature.mapper.BatteryOutliersMapper</value>
                </property>
                <property>
                    <name>mapreduce.combine.class</name>
                    <value>com.revature.reducer.BatteryTestCountsCombiner</value>
                </property>
                <property>
                    <name>mapreduce.reduce.class</name>
                    <value>com.revature.reducer.BatteryOutlierReducer</value>
                </property>
                <property>
                    <name>mapreduce.job.inputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.input.TextInputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.outputformat.class</name>
                    <value>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</value>
                </property>
                <property>
                    <name>mapreduce.job.input.key.class</name>
                    <value>org.apache.hadoop.io.LongWritable</value>
                </property>
                <property>
                    <name>mapreduce.job.input.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${IntermediateDataOutput}/part-r-00000</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${BatteryOutlierOutput}</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to='join_node'/>
        <error to='kill'/>
    </action>

    <join name = 'join_node' to = 'end'/>

    <kill name='kill'>
        <message>Map/Reduce failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>
    <end name='end'/>
</workflow-app>
